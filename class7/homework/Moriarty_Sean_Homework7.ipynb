{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We covered a lot of information today and I'd like you to practice developing classification trees on your own. For each exercise, work through the problem, determine the result, and provide the requested interpretation in comments along with the code. The point is to build classifiers, not necessarily good classifiers (that will hopefully come later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the iris dataset and create a holdout set that is 50% of the data (50% in training and 50% in test). Output the results (don't worry about creating the tree visual unless you'd like to) and discuss them briefly (are they good or not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confussion_matrix=True):\n",
    "    y_pred=clf.predict(X)\n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\")\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y,y_pred),\"\\n\")\n",
    "    if show_confussion_matrix:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(metrics.confusion_matrix(y,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = iris.data[:,2:]\n",
    "y = iris.target\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.50,train_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.000 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        23\n",
      "          1       1.00      1.00      1.00        25\n",
      "          2       1.00      1.00      1.00        27\n",
      "\n",
      "avg / total       1.00      1.00      1.00        75\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[23  0  0]\n",
      " [ 0 25  0]\n",
      " [ 0  0 27]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_test,y_test,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.987 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       1.00      0.96      0.98        25\n",
      "          2       0.96      1.00      0.98        23\n",
      "\n",
      "avg / total       0.99      0.99      0.99        75\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[27  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  0 23]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we accidentally misclassified one item, putting a thing 2 into the thing 3 pile. 98.7% accuracy seems pretty good to me, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Redo the model with a 75% - 25% training/test split and compare the results. Are they better or worse than before? Discuss why this may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.991 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        42\n",
      "          1       1.00      0.97      0.98        33\n",
      "          2       0.97      1.00      0.99        37\n",
      "\n",
      "avg / total       0.99      0.99      0.99       112\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[42  0  0]\n",
      " [ 0 32  1]\n",
      " [ 0  0 37]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still only missed one, making the exact same mistake. There must be a heavily overlapping area of these two species that confuses the model. Either way, we got the same number of errors with twice the training data, which seems pretty bad. I wonder how much we can cut it before it makes a difference in accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.993 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        47\n",
      "          1       1.00      0.98      0.99        48\n",
      "          2       0.98      1.00      0.99        48\n",
      "\n",
      "avg / total       0.99      0.99      0.99       143\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[47  0  0]\n",
      " [ 0 47  1]\n",
      " [ 0  0 48]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.95,train_size=0.05)\n",
    "measure_performance(x_test,y_test, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird. Small dataset, I guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the breast cancer dataset (`datasets.load_breast_cancer()`) and perform basic exploratory analysis. What attributes to we have? What are we trying to predict?\n",
    "For context of the data, see the documentation here: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "1) ID number\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "c) perimeter\n",
    "d) area\n",
    "e) smoothness (local variation in radius lengths)\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "h) concave points (number of concave portions of the contour)\n",
    "i) symmetry\n",
    "j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = bc.data[:,2:]\n",
    "y = bc.target\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using the breast cancer data, create a classifier to predict the type of seed. Perform the above hold out evaluation (50-50 and 75-25) and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.50,train_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.000 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       102\n",
      "          1       1.00      1.00      1.00       182\n",
      "\n",
      "avg / total       1.00      1.00      1.00       284\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[102   0]\n",
      " [  0 182]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.000 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       110\n",
      "          1       1.00      1.00      1.00       175\n",
      "\n",
      "avg / total       1.00      1.00      1.00       285\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[110   0]\n",
      " [  0 175]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_test,y_test,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.000 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       161\n",
      "          1       1.00      1.00      1.00       265\n",
      "\n",
      "avg / total       1.00      1.00      1.00       426\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[161   0]\n",
      " [  0 265]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to be honest, I barely have any idea what I'm looking at here. I believe we are trying to predict malignancy of cancer cells, but my understanding of the process to get here is such that I really just copied what we did in class and applied it here. I couldn't say that I used all 10 of the variables described by the dataset or that I just applied the diagnosis to itself as a predictor. This is about as clear as mud to me currently. Maybe a visual tree will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(x,y)\n",
    "with open(\"bc.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(dt, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.unlink('bc.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = StringIO() \n",
    "tree.export_graphviz(dt, out_file=dot_data) #brew install graphviz\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"bc.pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"800\"\n",
       "            src=\"bc.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb37ac8c4a8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"bc.pdf\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I guess we did actually take in the data correctly, but the model was suspiciously accurate because it has a lot of information to generate the prediction with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
