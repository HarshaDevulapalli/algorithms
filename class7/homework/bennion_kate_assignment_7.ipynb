{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the iris dataset and create a holdout set that is 50% of the data (50% in training and 50% in test). Output the results (don't worry about creating the tree visual unless you'd like to) and discuss them briefly (are they good or not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from pandas.tools.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = iris.data[:,2:]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.5,train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confussion_matrix=True):\n",
    "    y_pred=clf.predict(X)\n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\")\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y,y_pred),\"\\n\")\n",
    "    if show_confussion_matrix:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(metrics.confusion_matrix(y,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.000 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        26\n",
      "          1       1.00      1.00      1.00        21\n",
      "          2       1.00      1.00      1.00        28\n",
      "\n",
      "avg / total       1.00      1.00      1.00        75\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[26  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 28]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#They were 100% accurate for teh test data, which is good, but also has me suspicious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo the model with a 75% - 25% training/test split and compare the results. Are they better or worse than before? Discuss why this may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confussion_matrix=True):\n",
    "    y_pred=clf.predict(X)\n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\")\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y,y_pred),\"\\n\")\n",
    "    if show_confussion_matrix:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(metrics.confusion_matrix(y,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.991 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        40\n",
      "          1       1.00      0.97      0.99        40\n",
      "          2       0.97      1.00      0.98        32\n",
      "\n",
      "avg / total       0.99      0.99      0.99       112\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[40  0  0]\n",
      " [ 0 39  1]\n",
      " [ 0  0 32]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#They are slightly less accurate than before -- one of the results for the second group was placed in the third group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the breast cancer dataset (datasets.load_breast_cancer()) and perform basic exploratory analysis. What attributes to we have? What are we trying to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brc = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Breast Cancer Wisconsin (Diagnostic) Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n        \\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n        \\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ======= ========\\n                                           Min     Max\\n    ===================================== ======= ========\\n    radius (mean):                         6.981   28.11\\n    texture (mean):                        9.71    39.28\\n    perimeter (mean):                      43.79   188.5\\n    area (mean):                           143.5   2501.0\\n    smoothness (mean):                     0.053   0.163\\n    compactness (mean):                    0.019   0.345\\n    concavity (mean):                      0.0     0.427\\n    concave points (mean):                 0.0     0.201\\n    symmetry (mean):                       0.106   0.304\\n    fractal dimension (mean):              0.05    0.097\\n    radius (standard error):               0.112   2.873\\n    texture (standard error):              0.36    4.885\\n    perimeter (standard error):            0.757   21.98\\n    area (standard error):                 6.802   542.2\\n    smoothness (standard error):           0.002   0.031\\n    compactness (standard error):          0.002   0.135\\n    concavity (standard error):            0.0     0.396\\n    concave points (standard error):       0.0     0.053\\n    symmetry (standard error):             0.008   0.079\\n    fractal dimension (standard error):    0.001   0.03\\n    radius (worst):                        7.93    36.04\\n    texture (worst):                       12.02   49.54\\n    perimeter (worst):                     50.41   251.2\\n    area (worst):                          185.2   4254.0\\n    smoothness (worst):                    0.071   0.223\\n    compactness (worst):                   0.027   1.058\\n    concavity (worst):                     0.0     1.252\\n    concave points (worst):                0.0     0.291\\n    symmetry (worst):                      0.156   0.664\\n    fractal dimension (worst):             0.055   0.208\\n    ===================================== ======= ========\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\nA few of the images can be found at\\nhttp://www.cs.wisc.edu/~street/images/\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\nReferences\\n----------\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870, \\n     San Jose, CA, 1993. \\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.\\n',\n",
       " 'data': array([[  1.79900000e+01,   1.03800000e+01,   1.22800000e+02, ...,\n",
       "           2.65400000e-01,   4.60100000e-01,   1.18900000e-01],\n",
       "        [  2.05700000e+01,   1.77700000e+01,   1.32900000e+02, ...,\n",
       "           1.86000000e-01,   2.75000000e-01,   8.90200000e-02],\n",
       "        [  1.96900000e+01,   2.12500000e+01,   1.30000000e+02, ...,\n",
       "           2.43000000e-01,   3.61300000e-01,   8.75800000e-02],\n",
       "        ..., \n",
       "        [  1.66000000e+01,   2.80800000e+01,   1.08300000e+02, ...,\n",
       "           1.41800000e-01,   2.21800000e-01,   7.82000000e-02],\n",
       "        [  2.06000000e+01,   2.93300000e+01,   1.40100000e+02, ...,\n",
       "           2.65000000e-01,   4.08700000e-01,   1.24000000e-01],\n",
       "        [  7.76000000e+00,   2.45400000e+01,   4.79200000e+01, ...,\n",
       "           0.00000000e+00,   2.87100000e-01,   7.03900000e-02]]),\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "        'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "        'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "        'worst concave points', 'worst symmetry', 'worst fractal dimension'], \n",
       "       dtype='<U23'),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], \n",
       "       dtype='<U9')}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are trying to predict (whether the tumor is) malignant or benign\n",
    "#The attributes we have are: radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the breast cancer data, create a classifier to predict the type of seed. Perform the above hold out evaluation (50-50 and 75-25) and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.5,train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confussion_matrix=True):\n",
    "    y_pred=clf.predict(X)\n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\")\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y,y_pred),\"\\n\")\n",
    "    if show_confussion_matrix:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(metrics.confusion_matrix(y,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.000 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       1.00      1.00      1.00        27\n",
      "          2       1.00      1.00      1.00        27\n",
      "\n",
      "avg / total       1.00      1.00      1.00        75\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[21  0  0]\n",
      " [ 0 27  0]\n",
      " [ 0  0 27]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.973 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        38\n",
      "          1       0.95      0.98      0.96        41\n",
      "          2       0.97      0.94      0.95        33\n",
      "\n",
      "avg / total       0.97      0.97      0.97       112\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[38  0  0]\n",
      " [ 0 40  1]\n",
      " [ 0  2 31]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Again, as with the irises, when larger training set was used accuracy decreased. \n",
    "#It actually decreased more as it went -- one was wrong from the second set, and two were wrong from the third set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
